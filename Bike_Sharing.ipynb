{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing in Washington D.C.\n",
    "\n",
    "Statistical Programming - Python | MBD OCT 2018 | O17 (Group G)  \n",
    "*IE School of Human Sciences and Technology*  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This case study of the Washington D.C Bike Sharing System aims to predict the total number of users on an hourly basis. The dataset is [available on Kaggle](https://www.kaggle.com/marklvl/bike-sharing-dataset/home). It contains usage information of years 2011 and 2012.\n",
    "\n",
    "All the files of this project are saved in a [GitHub repository](https://github.com/ashomah/Bike-Sharing-in-Washington)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses a set of libraries for data manipulation, ploting and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/stavrostsentemeidis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Loading Libraries\n",
    "import pandas as pd #Data Manipulation - version 0.23.4\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np #Data Manipulation - version 1.15.4\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt #Plotting - version 3.0.2\n",
    "import matplotlib.ticker as ticker #Plotting - version 3.0.2\n",
    "import seaborn as sns #Plotting - version 0.9.0\n",
    "sns.set(style='white')\n",
    "\n",
    "from sklearn import preprocessing #Preprocessing - version 0.20.1\n",
    "from sklearn.preprocessing import MinMaxScaler #Preprocessing - version 0.20.1\n",
    "from sklearn.preprocessing import PolynomialFeatures #Preprocessing - version 0.20.1\n",
    "\n",
    "from scipy.stats import skew, boxcox_normmax #Preprocessing - version 1.1.0\n",
    "from scipy.special import boxcox1p #Preprocessing - version 1.1.0\n",
    "import statsmodels.api as sm #Outliers detection - version 0.9.0\n",
    "\n",
    "from sklearn.model_selection import train_test_split #Train/Test Split - version 0.20.1\n",
    "from sklearn.model_selection import TimeSeriesSplit,cross_validate #Timeseries CV - version 0.20.1\n",
    "from sklearn import datasets, linear_model #Model - version 0.20.1\n",
    "from sklearn.linear_model import LinearRegression #Model - version 0.20.1\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score #Metrics - version 0.20.1\n",
    "from sklearn.metrics import accuracy_score #Metrics - version 0.20.1\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict # CV - version 0.20.1\n",
    "from sklearn.feature_selection import RFE #Feature Selection - version 0.20.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is stored in the [GitHub repository](https://github.com/ashomah/Bike-Sharing-in-Washington) consisting in two CSV file: `day.csv` and `hour.csv`. The files are loaded directly from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_df = pd.read_csv(\"https://raw.githubusercontent.com/ashomah/Bike-Sharing-in-Washington/master/Bike-Sharing-Dataset/hour.csv\")\n",
    "hours_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_df = pd.read_csv(\"https://raw.githubusercontent.com/ashomah/Bike-Sharing-in-Washington/master/Bike-Sharing-Dataset/day.csv\")\n",
    "days_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables Types and Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first stage of this analysis is to describe the dataset, understand the meaning of variable and perform the necessary adjustments to ensure that the data will be proceeded correctly during the Machine Learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the data frame\n",
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('hour.csv:', hours_df.shape[0],'rows |', hours_df.shape[1], 'columns'))\n",
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('day.csv:', days_df.shape[0],'rows |', days_df.shape[1], 'columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe each variable\n",
    "def df_desc(df):\n",
    "    import pandas as pd\n",
    "    desc = pd.DataFrame({'dtype': df.dtypes,\n",
    "                         'NAs': df.isna().sum(),\n",
    "                         'Numerical': (df.dtypes != 'object') & (df.dtypes != 'datetime64[ns]') & (df.apply(lambda column: column == 0).sum() + df.apply(lambda column: column == 1).sum() != len(df)),\n",
    "                         'Boolean': df.apply(lambda column: column == 0).sum() + df.apply(lambda column: column == 1).sum() == len(df),\n",
    "                         'Categorical': df.dtypes == 'object',\n",
    "                         'Date': df.dtypes == 'datetime64[ns]',\n",
    "                        })\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc(days_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc(hours_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset `day.csv` consists in 731 rows and 16 columns. The dataset `hour.csv` consists in 17,379 rows and 17 columns. Both datasets have the same columns, with an additional column for hours in `hour.csv`.\n",
    "\n",
    "Each row provides information for each day or each hour. None of the attributes contains any NA. Four (4) of these attributes contain decimal numbers, nine (9) contain integers, three (3) contain booleans, and one (1) contains date values stored as string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better readability, the columns of both data frames are renamed and data types are adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HOURS DATASET\n",
    "# Renaming columns names to more readable names\n",
    "hours_df.rename(columns={'instant':'id',\n",
    "                        'dteday':'date',\n",
    "                        'weathersit':'weather_condition',\n",
    "                        'hum':'humidity',\n",
    "                        'mnth':'month',\n",
    "                        'cnt':'total_bikes',\n",
    "                        'hr':'hour',\n",
    "                        'yr':'year',\n",
    "                        'temp':'actual_temp',\n",
    "                        'atemp':'feeling_temp'},\n",
    "                inplace=True)\n",
    "\n",
    "# Date time conversion\n",
    "hours_df.date = pd.to_datetime(hours_df.date, format='%Y-%m-%d')\n",
    "\n",
    "# Categorical variables\n",
    "for column in ['season', 'holiday', 'weekday', 'workingday', 'weather_condition','month', 'year','hour']:\n",
    "    hours_df[column] = hours_df[column].astype('category')\n",
    "    \n",
    "# DAYS DATASET\n",
    "# Renaming columns names to more readable names\n",
    "days_df.rename(columns={'instant':'id',\n",
    "                        'dteday':'date',\n",
    "                        'weathersit':'weather_condition',\n",
    "                        'hum':'humidity',\n",
    "                        'mnth':'month',\n",
    "                        'cnt':'total_bikes',\n",
    "                        'yr':'year',\n",
    "                        'temp':'actual_temp',\n",
    "                        'atemp':'feeling_temp'},\n",
    "               inplace=True)\n",
    "\n",
    "# Date time conversion\n",
    "days_df.date = pd.to_datetime(days_df.date, format='%Y-%m-%d')\n",
    "\n",
    "# Categorical variables\n",
    "for column in ['season', 'holiday', 'weekday', 'workingday', 'weather_condition','month', 'year']:\n",
    "    days_df[column] = days_df[column].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists values of categorical variables\n",
    "categories = {'season': hours_df['season'].unique().tolist(),\n",
    "              'year':hours_df['year'].unique().tolist(),\n",
    "              'month':hours_df['month'].unique().tolist(),\n",
    "              'hour':hours_df['hour'].unique().tolist(),\n",
    "              'holiday':hours_df['holiday'].unique().tolist(),\n",
    "              'weekday':hours_df['weekday'].unique().tolist(),\n",
    "              'workingday':hours_df['workingday'].unique().tolist(),\n",
    "              'weather_condition':hours_df['weather_condition'].unique().tolist(),\n",
    "             }\n",
    "for i in sorted(categories.keys()):\n",
    "    print(i+\":\")\n",
    "    print(categories[i])\n",
    "    if i != sorted(categories.keys())[-1] :print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_desc(hours_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists values of categorical variables\n",
    "categories = {'season': days_df['season'].unique().tolist(),\n",
    "              'year':days_df['year'].unique().tolist(),\n",
    "              'month':days_df['month'].unique().tolist(),\n",
    "              'holiday':days_df['holiday'].unique().tolist(),\n",
    "              'weekday':days_df['weekday'].unique().tolist(),\n",
    "              'workingday':days_df['workingday'].unique().tolist(),\n",
    "              'weather_condition':days_df['weather_condition'].unique().tolist(),\n",
    "             }\n",
    "for i in sorted(categories.keys()):\n",
    "    print(i+\":\")\n",
    "    print(categories[i])\n",
    "    if i != sorted(categories.keys())[-1] :print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc(days_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this study, we will only work with the dataset `hours`. The datasets contain 17 variables with no NAs:\n",
    "\n",
    "- `id`: numerical, integer values.  \n",
    "  *Record index. __This variable won't be considered in the study.__*\n",
    "  \n",
    "  \n",
    "- `date`: numerical, date values.  \n",
    "  *Date.*\n",
    "\n",
    "\n",
    "- `season`: encoded categorical, integer between 1 and 4.  \n",
    "  *Season: 2=Spring, 3=Summer, 4=Fall, 1=Winter.*  \n",
    "  *__Note: the seasons mentioned on the Kaggle page didn't correspond to the real seasons. We readjusted the parameters accordingly.__*\n",
    "\n",
    "\n",
    "- `year`: encoded categorical, integer between 0 and 1.  \n",
    "  *Year: 0=2011, 1=2012.*\n",
    "  \n",
    "  \n",
    "- `month`: encoded categorical, integer between 1 and 12.  \n",
    "  *Month.*\n",
    "  \n",
    "  \n",
    "- `hour`: encoded categorical, integer between 1 and 23.  \n",
    "  *Hour.*\n",
    "  \n",
    "  \n",
    "- `holiday`: encoded categorical, boolean.  \n",
    "  *Flag indicating if the day is a holiday.*\n",
    "\n",
    "\n",
    "- `weekday`: encoded categorical, integer between 0 and 6.  \n",
    "  *Day of the week (0=Sunday, ... 6=Saturday).*\n",
    "\n",
    "\n",
    "- `workingday`: encoded categorical, boolean.  \n",
    "  *Flag indicating if the day is a working day.*\n",
    "  \n",
    "  \n",
    "- `weather_condition`: encoded categorical, integer between 1 and 4.  \n",
    "  *Weather condition (1=Clear, 2=Mist, 3=Light Rain, 4=Heavy Rain).*\n",
    "\n",
    "\n",
    "- `actual_temp`: numerical, decimal values between 0 and 1.  \n",
    "  *Normalized temperature in Celsius (min = -16, max = +50).*\n",
    "\n",
    "\n",
    "- `feeling_temp`: numerical, decimal values between 0 and 1.  \n",
    "  *Normalized feeling temperature in Celsius (min = -8, max = +39).*\n",
    "\n",
    "\n",
    "- `humidity`: numerical, decimal values between 0 and 1.  \n",
    "  *Normalized humidity.*\n",
    "\n",
    "\n",
    "- `windspeed`: numerical, decimal values between 0 and 1.  \n",
    "  *Normalized wind speed.*\n",
    "\n",
    "\n",
    "- `casual`: numerical, integer.  \n",
    "  *Count of casual users. This variable won't be considered in the study.*\n",
    "\n",
    "\n",
    "- `registered`: numerical, integer.  \n",
    "  *Count of registered users. This variable won't be considered in the study.*\n",
    "\n",
    "\n",
    "- `total_bikes`: numerical, integer.  \n",
    "  *Count of total rental bikes (casual+registered). This is the __target variable__ of the study, the one to be modelled.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove variable id\n",
    "hours_df= hours_df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization over the two years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this study is to build a model to predict the value of the variable `total_bikes`, based on the other variables available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_bikes evolution per day\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = hours_df.date,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the two years dataset, it seems that the utilization of the bike sharing service has increased over the period. The number of bikes rented per day also seems to vary depending on the season, with Spring and Summer months being showing a higher utilization of the service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_bikes by Month - Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "g = sns.lineplot(x = hours_df.month,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue') \\\n",
    "   .axes.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.xticks([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Month - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(x = hours_df.month,\n",
    "            y = hours_df.total_bikes,\n",
    "             color = 'steelblue') \\\n",
    "   .axes.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average utilization per month seems to increase between April and October, with a higher variance too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Hour - Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = hours_df.hour,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "plt.xticks([0, 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Hour - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(x = hours_df.hour,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Hour - Distribution\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot(hours_df.total_bikes,\n",
    "             bins = 100,\n",
    "             color = 'steelblue').axes.set(xlim = (min(hours_df.total_bikes),max(hours_df.total_bikes)),\n",
    "                                           xticks = [0,100,200,300,400,500,600,700,800,900,1000])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utilization seems really similar over the day, with 2 peaks around 8am and between 5pm and 6pm. The box plot shows potential outliers in the data, which will be removed after the Feature Construction stage. It also highlight an important variance during day time, especially at peak times. The distribution plot shows that utilization is most of the time below 40 bikes simultaneously, and can reach about 1,000 bikes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Season - Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = hours_df.season,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue') \\\n",
    "   .axes.set_xticklabels(['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "plt.xticks([1,2,3,4])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Season - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(x = hours_df.season,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue') \\\n",
    "   .axes.set_xticklabels(['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summer appears to be the high season, with Spring and Fall having similar utilization shapes. Winter logically appears to be the low season with, however, potential utilization peaks which can reach the same number of bikes than in high season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_bikes by Holidays - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(x = hours_df.holiday,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue') \\\n",
    "   .axes.set_xticklabels(['Normal Day', 'Holiday'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilization of bikes during holidays seems lower and with less peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_bikes by Weekday - Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = hours_df.weekday,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue') \\\n",
    "   .axes.set_xticklabels(['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'])\n",
    "plt.xticks([0,1,2,3,4,5,6])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Weekday - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(x = hours_df.weekday,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue') \\\n",
    "   .axes.set_xticklabels(['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average utilization per hour seems higher at the end of the week, but overall, weekends appear to have lower frequentation and weekdays have higher peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Working Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_bikes by Working Day - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(x = hours_df.workingday,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue') \\\n",
    "   .axes.set_xticklabels(['Non Working Day', 'Working Day'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilization seems higher during working days, with higher peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Weather Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_bikes by Weather Condition - Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = hours_df.weather_condition,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue') \\\n",
    "   .axes.set_xticklabels(['Clear', 'Mist', 'Light Rain', 'Heavy Rain'])\n",
    "plt.xticks([1,2,3,4])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Weather Condition - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(x = hours_df.weather_condition,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue') \\\n",
    "   .axes.set_xticklabels(['Clear', 'Mist', 'Light Rain', 'Heavy Rain'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, bike sharing utilization is getting worse with bad weather."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Actual Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_bikes by Actual Temperature - Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = hours_df.actual_temp,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Actual Temperature - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(x = hours_df.actual_temp,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utilization is almost inexistant for sub-zero temperatures. It then grows with the increase of temperature, but drops down when it gets extremely hot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Feeling Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_bikes by Feeling Temperature - Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = hours_df.feeling_temp,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Feeling Temperature - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(x = hours_df.feeling_temp,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utilization by feeling temperature follows the same rules than by actual temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Humidity - Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = hours_df.humidity,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Humidity - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(x = hours_df.humidity,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utilization of bike sharing services is decreasing with the increase of humidity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Wind Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_bikes by Wind Speed - Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = hours_df.windspeed,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Wind Speed - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(x = hours_df.windspeed,\n",
    "             y = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stronger wind seems to discourage users to use the bike sharing service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Casual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_bikes by Casual - Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(y = hours_df.casual,\n",
    "             x = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "sns.lineplot(y = hours_df.total_bikes,\n",
    "             x = hours_df.total_bikes,\n",
    "             color = 'orange')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Casual - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(y = hours_df.casual,\n",
    "            x = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "sns.lineplot(y = hours_df.total_bikes,\n",
    "             x = hours_df.total_bikes,\n",
    "             color = 'orange')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of casual users seems to be quite low compared to the total users, but there are peaks of activity when total utilization reaches values between 500 and 800 bikes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike sharing utilization by Registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_bikes by Registered - Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(y = hours_df.registered,\n",
    "             x = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "sns.lineplot(y = hours_df.total_bikes,\n",
    "             x = hours_df.total_bikes,\n",
    "             color = 'orange')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Total_bikes by Registered - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(y = hours_df.registered,\n",
    "            x = hours_df.total_bikes,\n",
    "             color = 'steelblue')\n",
    "sns.lineplot(y = hours_df.total_bikes,\n",
    "             x = hours_df.total_bikes,\n",
    "             color = 'orange')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of registered users is usually high, compared to the total number of bikes. There are however drops between 500 and 800 total users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casual vs Registered Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas_reg = pd.DataFrame(hours_df.registered)\n",
    "cas_reg['casual'] = hours_df.casual\n",
    "cas_reg['total_bikes'] = hours_df.total_bikes\n",
    "cas_reg['ratio_cas_tot'] = np.where(cas_reg.total_bikes == 0,0,round(cas_reg.casual / cas_reg.total_bikes,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ratio of Casual Users - Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(y = cas_reg.ratio_cas_tot,\n",
    "             x = cas_reg.total_bikes,\n",
    "             color = 'steelblue')\n",
    "plt.axhline(1, color='orange')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ratio of Casual Users - Box Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(y = cas_reg.ratio_cas_tot,\n",
    "            x = cas_reg.total_bikes,\n",
    "             color = 'steelblue')\n",
    "plt.axhline(1, color='orange')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of Casual Users - Distribution\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot(cas_reg.ratio_cas_tot,\n",
    "             bins = 100,\n",
    "             color = 'steelblue').axes.set(xlim = (min(cas_reg.ratio_cas_tot),max(cas_reg.ratio_cas_tot)))\n",
    "plt.axvline(0.5, color='orange', linestyle='--')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio of casual users is most of the time lower than the ratio of registered users, mainly lower than 30% of total users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total_Bikes by Hour with Holiday Hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "g = sns.pointplot(y = hours_df.total_bikes,\n",
    "             x = hours_df.hour,\n",
    "             hue = hours_df.holiday.astype('int'),\n",
    "             palette = 'viridis',\n",
    "             markers='.',\n",
    "             errwidth = 1.5)\n",
    "g_legend = g.axes.get_legend()\n",
    "g_labels = ['Normal Day', 'Holiday']\n",
    "for t, l in zip(g_legend.texts, g_labels): t.set_text(l)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utilization by hour during normal days differs from the utilization during holidays. During normal days, two (2) peaks are present during commute times (around 8am and 5-6pm), while during holidays, utilization is higher during the day between 10am and 8pm. Utilization during holidays also shows a higher variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total_Bikes by Hour with Working Day Hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "g = sns.pointplot(y = hours_df.total_bikes,\n",
    "             x = hours_df.hour,\n",
    "             hue = hours_df.workingday.astype('int'),\n",
    "             palette = 'viridis',\n",
    "             markers='.',\n",
    "             errwidth = 1.5)\n",
    "g_legend = g.axes.get_legend()\n",
    "g_labels = ['Non Working Day', 'Working Day']\n",
    "for t, l in zip(g_legend.texts, g_labels): t.set_text(l)\n",
    "plt.axhline(hours_df.total_bikes.mean()+0.31*hours_df.total_bikes.mean(), color='orange')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite similar than the utilization by holiday, the utilization by hour during working days differs from the utilization during non working days. During working days, two (2) peaks are present during commute times (around 8am and 5-6pm), while during non working days, utilization is higher during the day between 10am and 8pm. Interestingly, utilization during non working day seems to have less variance than during holidays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total_Bikes by Hour with Weekday Hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "g = sns.pointplot(y = hours_df.total_bikes,\n",
    "             x = hours_df.hour,\n",
    "             hue = hours_df.weekday.astype('int'),\n",
    "             palette = 'viridis',\n",
    "             markers='.',\n",
    "             errwidth = 1.5)\n",
    "g_legend = g.axes.get_legend()\n",
    "g_labels = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "for t, l in zip(g_legend.texts, g_labels): t.set_text(l)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utilization by hour during weekdays differs from the utilization during weekends. During weekdays, two (2) peaks are present during commute times (around 8am and 5-6pm), while during weekends, utilization is higher during the day between 10am and 6pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total_Bikes by Hour with Weekday Hue for Registered Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "g = sns.pointplot(y = hours_df.registered,\n",
    "             x = hours_df.hour,\n",
    "             hue = hours_df.weekday.astype('int'),\n",
    "             palette = 'viridis',\n",
    "             markers='.',\n",
    "             errwidth = 1.5)\n",
    "g_legend = g.axes.get_legend()\n",
    "g_labels = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "for t, l in zip(g_legend.texts, g_labels): t.set_text(l)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registered users seem to be responsible for the two (2) peaks during commute times. They still use the bikes during the weekends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total_Bikes by Hour with Weekday Hue for Casual Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "g = sns.pointplot(y = hours_df.casual,\n",
    "             x = hours_df.hour,\n",
    "             hue = hours_df.weekday.astype('int'),\n",
    "             palette = 'viridis',\n",
    "             markers='.',\n",
    "             errwidth = 1.5)\n",
    "g_legend = g.axes.get_legend()\n",
    "g_labels = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "for t, l in zip(g_legend.texts, g_labels): t.set_text(l)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casual users are mainly using the bikes during the weekends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total_Bikes by Hour with Weather Conditions Hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "g = sns.pointplot(y = hours_df.total_bikes,\n",
    "             x = hours_df.hour,\n",
    "             hue = hours_df.weather_condition.astype('int'),\n",
    "             palette = 'viridis',\n",
    "             markers='.',\n",
    "             errwidth = 1.5)\n",
    "g_legend = g.axes.get_legend()\n",
    "g_labels = ['Clear', 'Mist', 'Light Rain', 'Heavy Rain']\n",
    "for t, l in zip(g_legend.texts, g_labels): t.set_text(l)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather seems to have a consistent impact on the utilization by hour, except for mist which doesn't seem to discourage morning commuters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total_Bikes by Hour with Seasons Hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "g = sns.pointplot(y = hours_df.total_bikes,\n",
    "             x = hours_df.hour,\n",
    "             hue = hours_df.season.astype('int'),\n",
    "             palette = 'viridis',\n",
    "             markers='.',\n",
    "             errwidth = 1.5)\n",
    "g_legend = g.axes.get_legend()\n",
    "g_labels = ['Winter', 'Spring', 'Summer', 'Fall']\n",
    "for t, l in zip(g_legend.texts, g_labels): t.set_text(l)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The season seems to have a consistent impact on the utilization by hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Humidity by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(x = hours_df.actual_temp,\n",
    "            y = hours_df.humidity,\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The season seems to have a consistent impact on the utilization by hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlation analysis will allow to identify relationships between the dataset variables. A plot of their distributions highlighting the value of the target variable might also reveal some patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hours_df_corr = hours_df.copy()\n",
    "hours_df_corr = hours_df_corr.drop(['date', 'year', 'month', 'hour', 'casual', 'registered', 'total_bikes'], axis=1)\n",
    "for column in hours_df_corr.columns:\n",
    "    hours_df_corr[column] = hours_df_corr[column].astype('float')\n",
    "    \n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(hours_df_corr.corr(), \n",
    "            cmap=sns.diverging_palette(220, 20, n=7), vmax=1.0, vmin=-1.0, linewidths=0.1,\n",
    "            annot=True, annot_kws={\"size\": 8}, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "axs = fig.subplots(2,4)\n",
    "\n",
    "sns.scatterplot(hours_df['actual_temp'], hours_df['feeling_temp'], palette=('viridis'), ax = axs[0,0])\n",
    "\n",
    "sns.scatterplot(hours_df['humidity'],hours_df['windspeed'], palette=('viridis'), ax = axs[0,1])\n",
    "\n",
    "sns.countplot(hours_df['holiday'],hue=hours_df['workingday'], palette=('viridis'), ax = axs[0,2])\n",
    "axs[0,2].set_xticklabels(labels=['Normal Day', 'Holiday'])\n",
    "g_legend = axs[0,2].get_legend()\n",
    "g_labels = ['Non Working', 'Working']\n",
    "for t, l in zip(g_legend.texts, g_labels): t.set_text(l)\n",
    "\n",
    "sns.boxplot(hours_df['weather_condition'], hours_df['humidity'], palette=('viridis'), ax = axs[0,3])\n",
    "axs[0,3].set_xticklabels(labels=['Clear', 'Mist', 'L. Rain', 'H. Rain'])\n",
    "\n",
    "sns.boxplot(hours_df['season'], hours_df['actual_temp'], palette=('viridis'), ax = axs[1,0])\n",
    "axs[1,0].set_xticklabels(labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "\n",
    "sns.boxplot(hours_df['season'], hours_df['feeling_temp'], palette=('viridis'), ax = axs[1,1])\n",
    "axs[1,1].set_xticklabels(labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "\n",
    "sns.boxplot(hours_df['season'], hours_df['humidity'], palette=('viridis'), ax = axs[1,2])\n",
    "axs[1,2].set_xticklabels(labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "\n",
    "sns.boxplot(hours_df['season'], hours_df['windspeed'], palette=('viridis'), ax = axs[1,3])\n",
    "axs[1,3].set_xticklabels(labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix shows a high correlation between `actual_temp` and `feeling_temp`. Thus, only the `actual_temp` variable will be used in the study, and the `feeling_temp` will be removed from the dataset.\n",
    "\n",
    "Another interesting relationship exists between `holiday` and `workingday`. Every holiday is a non-working day. Based on previous plots, the utilization of bikes per hour based on `workingday` seems to be more stable than based on `holiday`, thus the variable `holiday` will be removed.\n",
    "\n",
    "Some other logical correlations can be found between meteorological conditions and seasons, but they are not strong enough to lighten the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_prep_scaled = hours_df.copy().drop(['date','casual', 'registered', 'holiday','feeling_temp'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_prep_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "hours_prep_scaled[['actual_temp', 'humidity', 'windspeed', 'total_bikes']] = pd.DataFrame(scaler.fit_transform(hours_prep_scaled[['actual_temp', 'humidity','windspeed', 'total_bikes']]))\n",
    "hours_prep_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_skewness(df):\n",
    "    numeric_dtypes = ['int16', 'int32', 'int64', \n",
    "                      'float16', 'float32', 'float64']\n",
    "    numeric_features = []\n",
    "    for i in df.columns:\n",
    "        if df[i].dtype in numeric_dtypes: \n",
    "            numeric_features.append(i)\n",
    "\n",
    "    feature_skew = df[numeric_features].apply(\n",
    "        lambda x: skew(x)).sort_values(ascending=False)\n",
    "    skews = pd.DataFrame({'skew':feature_skew})\n",
    "    return feature_skew, numeric_features\n",
    "\n",
    "def fix_skewness(df):\n",
    "    feature_skew, numeric_features = feature_skewness(df)\n",
    "    high_skew = feature_skew[feature_skew > 0.5]\n",
    "    skew_index = high_skew.index\n",
    "    \n",
    "    for i in skew_index:\n",
    "        df[i] = boxcox1p(df[i], boxcox_normmax(df[i]+1))\n",
    "\n",
    "    skew_features = df[numeric_features].apply(\n",
    "        lambda x: skew(x)).sort_values(ascending=False)\n",
    "    skews = pd.DataFrame({'skew':skew_features})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_df_num = hours_df.select_dtypes(include = ['float64', 'int64']);\n",
    "hours_prep_scaled.hist(figsize=(15, 5), bins=50, xlabelsize=3, ylabelsize=3, color='steelblue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_prep_skew = fix_skewness(hours_prep_scaled)\n",
    "hours_prep_skew.hist(figsize=(15, 5), bins=50, xlabelsize=3, ylabelsize=3, color='steelblue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale and skewness of the dataset are corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_prep_encoded = hours_prep_skew.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_features(df):\n",
    "    columns = df.columns\n",
    "    return df.select_dtypes(include=[np.datetime64]).columns\n",
    "\n",
    "def numerical_features(df):\n",
    "    columns = df.columns\n",
    "    return df._get_numeric_data().columns\n",
    "\n",
    "def categorical_features(df):\n",
    "    numerical_columns = numerical_features(df)\n",
    "    date_columns = date_features(df)\n",
    "    return(list(set(df.columns) - set(numerical_columns) - set(date_columns) ))\n",
    "\n",
    "def onehot_encode(df):\n",
    "    numericals = df.get(numerical_features(df))\n",
    "    new_df = numericals.copy()\n",
    "    for categorical_column in categorical_features(df):\n",
    "        new_df = pd.concat([new_df, \n",
    "                            pd.get_dummies(df[categorical_column], \n",
    "                                           prefix=categorical_column)], \n",
    "                           axis=1)\n",
    "    return new_df\n",
    "\n",
    "def onehot_encode_single(df, col_to_encode, drop = True):\n",
    "    if type(col_to_encode) != str:\n",
    "        raise TypeError ('col_to_encode should be a string.')\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    if drop == True:\n",
    "        new_df = new_df.drop([col_to_encode], axis=1)\n",
    "\n",
    "    new_df = pd.concat([new_df, \n",
    "                        pd.get_dummies(df[col_to_encode],\n",
    "                                       prefix=col_to_encode)],\n",
    "                       axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_clean = onehot_encode(hours_prep_encoded)\n",
    "df_desc(hours_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "hours_clean.rename(columns={'year_0':'year_2011',\n",
    "                        'year_1':'year_2012',\n",
    "                        'season_1':'season_winter',\n",
    "                        'season_2':'season_spring',\n",
    "                        'season_3':'season_summer',\n",
    "                        'season_4':'season_fall',\n",
    "                        'workingday_0':'workingday_no',\n",
    "                        'workingday_1':'workingday_yes',\n",
    "                        'month_1':'month_jan',\n",
    "                        'month_2':'month_feb',\n",
    "                        'month_3':'month_mar',\n",
    "                        'month_4':'month_apr',\n",
    "                        'month_5':'month_may',\n",
    "                        'month_6':'month_jun',\n",
    "                        'month_7':'month_jul',\n",
    "                        'month_8':'month_aug',\n",
    "                        'month_9':'month_sep',\n",
    "                        'month_10':'month_oct',\n",
    "                        'month_11':'month_nov',\n",
    "                        'month_12':'month_dec',\n",
    "                        'weather_condition_1':'weather_condition_clear',\n",
    "                        'weather_condition_2':'weather_condition_mist',\n",
    "                        'weather_condition_3':'weather_condition_light_rain',\n",
    "                        'weather_condition_4':'weather_condition_heavy_rain',\n",
    "                        'weekday_0':'weekday_sunday',\n",
    "                        'weekday_1':'weekday_monday',\n",
    "                        'weekday_2':'weekday_tuesday',\n",
    "                        'weekday_3':'weekday_wednesday',\n",
    "                        'weekday_4':'weekday_thursday',\n",
    "                        'weekday_5':'weekday_friday',\n",
    "                        'weekday_6':'weekday_saturday'},\n",
    "                inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_clean.drop('workingday_no', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `workingday_no` has been removed, as complementary of `workingday_yes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is ready for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_features(df, target):\n",
    "    features = list(df)\n",
    "    features.remove(target)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'total_bikes'\n",
    "features = list_features(hours_clean, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hours_clean[features]\n",
    "X_train = X.loc[(X['year_2011']==1) | ((X['year_2012']==1) & (X['month_sep']==0) & (X['month_oct']==0) & (X['month_nov']==0) & (X['month_dec']==0)),features]\n",
    "X_test = X.loc[(X['year_2012']==1) & ((X['month_sep']==1) | (X['month_oct']==1) | (X['month_nov']==1) | (X['month_dec']==1)),features]\n",
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('X_train:', X_train.shape[0],'rows |', X_train.shape[1], 'columns'))\n",
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('X_test:', X_test.shape[0],'rows |', X_test.shape[1], 'columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train.groupby(['year_2011','year_2012','month_jan','month_feb','month_mar','month_apr','month_may','month_jun','month_jul','month_aug','month_sep','month_oct','month_nov','month_dec']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.groupby(['year_2011','year_2012','month_jan','month_feb','month_mar','month_apr','month_may','month_jun','month_jul','month_aug','month_sep','month_oct','month_nov','month_dec']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hours_clean.copy()\n",
    "y_train = y.loc[(y['year_2011']==1) | ((y['year_2012']==1) & (y['month_sep']==0) & (y['month_oct']==0) & (y['month_nov']==0) & (y['month_dec']==0)),:]\n",
    "y_test = y.loc[(y['year_2012']==1) & ((y['month_sep']==1) | (y['month_oct']==1) | (y['month_nov']==1) | (y['month_dec']==1)),:]\n",
    "y_train = pd.DataFrame(y_train[target])\n",
    "y_test = pd.DataFrame(y_test[target])\n",
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('y_train:', y_train.shape[0],'rows |', y_train.shape[1], 'columns'))\n",
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('y_test:', y_test.shape[0],'rows |', y_test.shape[1], 'columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:<35} {!r:>}'.format('Same indexes for X_train and y_train:', X_train.index.values.tolist() == y_train.index.values.tolist()))\n",
    "print('{:<35} {!r:>}'.format('Same indexes for X_test and y_test:', X_test.index.values.tolist() == y_test.index.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Features:',X.shape[0], 'items | ', X.shape[1],'columns'))\n",
    "print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Features Train:',X_train.shape[0], 'items | ', X_train.shape[1],'columns'))\n",
    "print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Features Test:',X_test.shape[0], 'items | ',  X_test.shape[1],'columns'))\n",
    "print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Target:',y.shape[0], 'items | ', 1,'columns'))\n",
    "print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Target Train:',y_train.shape[0], 'items | ', 1,'columns'))\n",
    "print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Target Test:',y_test.shape[0], 'items | ', 1,'columns'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Train Set is arbitrarily defined as all records until August 31st 2012, and the Test Set all records from September 1st 2012. Below function will be used to repeat the operation on future dataframes including new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_0(df, target, features):\n",
    "    X = df[features]\n",
    "    y = pd.DataFrame(df[target])\n",
    "    X_train = X.loc[(X['year_2011']==1) | ((X['year_2012']==1) & (X['month_sep']==0) & (X['month_oct']==0) & (X['month_nov']==0) & (X['month_dec']==0)),features]\n",
    "    X_test = X.loc[(X['year_2012']==1) & ((X['month_sep']==1) | (X['month_oct']==1) | (X['month_nov']==1) | (X['month_dec']==1)),features]\n",
    "    y_train = y.iloc[X_train.index.values.tolist()]\n",
    "    y_test = y.iloc[X_test.index.values.tolist()]\n",
    "    \n",
    "    print('{:<40} {!r:>}'.format('Same indexes for X and y:', X.index.values.tolist() == y.index.values.tolist()))\n",
    "    print('{:<40} {!r:>}'.format('Same indexes for X_train and y_train:', X_train.index.values.tolist() == y_train.index.values.tolist()))\n",
    "    print('{:<40} {!r:>}'.format('Same indexes for X_test and y_test:', X_test.index.values.tolist() == y_test.index.values.tolist()))\n",
    "    print()\n",
    "    print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Features:',X.shape[0], 'items | ', X.shape[1],'columns'))\n",
    "    print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Features Train:',X_train.shape[0], 'items | ', X_train.shape[1],'columns'))\n",
    "    print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Features Test:',X_test.shape[0], 'items | ',  X_test.shape[1],'columns'))\n",
    "    print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Target:',y.shape[0], 'items | ', 1,'columns'))\n",
    "    print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Target Train:',y_train.shape[0], 'items | ', 1,'columns'))\n",
    "    print('{:<15} {:>6} {:>6} {:>2} {:>6}'.format('Target Test:',y_test.shape[0], 'items | ', 1,'columns'))\n",
    "    print()\n",
    "    \n",
    "    return X, X_train, X_test, y, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "print('Intercept:', lm.intercept_)\n",
    "print('Coefficients:', lm.coef_)\n",
    "print('Mean squared error (MSE): {:.2f}'.format(mean_squared_error(y_test, y_pred)))\n",
    "print('Variance score (R2): {:.2f}'.format(r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model for our dataset obtains a R square of 0.76 with 57 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_ts(algorithm, X_train, y_train, n_splits):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    scores = cross_validate(algorithm, X_train, y_train, cv=tscv,\n",
    "                            scoring=('r2'),\n",
    "                            return_train_score=True)\n",
    "    print('Cross Validation Variance score (R2): {:.2f}'.format(scores['train_score'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_ts(lm,X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation used is a recursive time series split with 10 folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each new feature will be tested through below pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  matplotlib import pyplot\n",
    "def pipeline(df, target, algorithm, n_splits = 10):\n",
    "    \n",
    "    features = list_features(df, target)\n",
    "    X, X_train, X_test, y, y_train, y_test = train_test_split_0(df, target, features)\n",
    "    cross_val_ts(algorithm,X_train, y_train, n_splits)\n",
    "    lm.fit(X_train, y_train)\n",
    "    y_pred = lm.predict(X_test)\n",
    "    \n",
    "    y_test_prep = pd.concat([y_test,pd.DataFrame(pd.DatetimeIndex(hours_df['date']).strftime('%m-%d-%Y'))], axis=1, sort=False, ignore_index=False)\n",
    "    y_test_prep = y_test_prep.dropna()\n",
    "    y_test_prep = y_test_prep.set_index(0)\n",
    "    y_pred_prep = pd.DataFrame(y_pred)\n",
    "    y_total_prep = pd.concat([y_test_prep.reset_index(drop=False), y_pred_prep.reset_index(drop=True)], axis=1)\n",
    "    y_total_prep.columns = ['Date', 'Actual_Bikes', 'Predicted_Bikes']\n",
    "    y_total_prep = y_total_prep.set_index('Date')\n",
    "\n",
    "    print()\n",
    "    print('Intercept:', lm.intercept_)\n",
    "    print('Coefficients:', lm.coef_)\n",
    "    print('Mean squared error (MSE): {:.2f}'.format(mean_squared_error(y_test, y_pred)))\n",
    "    print('Variance score (R2): {:.2f}'.format(r2_score(y_test, y_pred)))\n",
    "       \n",
    "    # axes = y_total_prep.plot.line(subplots=True) subplots\n",
    "#     plt.figure(figsize=(15,5))\n",
    "#     y_total_prep.plot()\n",
    "#     pyplot.show()\n",
    "    g = sns.lineplot(data=y_total_prep, ci=None, lw=1, dashes=False)\n",
    "    g.set_xticks('')\n",
    "    g.legend(loc='lower left', ncol=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(hours_clean, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_FE_sel = hours_clean.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `day` is added to understand if patterns exist based on specific dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add the day from 'date'\n",
    "hours_FE1 = pd.concat([hours_FE_sel,pd.DataFrame(pd.DatetimeIndex(hours_df['date']).day)], axis=1, sort=False, ignore_index=False)\n",
    "hours_FE1.rename(columns={'date':'day'}, inplace=True)\n",
    "\n",
    "# Encode feature\n",
    "hours_FE1 = onehot_encode_single(hours_FE1, 'day')\n",
    "df_desc(hours_FE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(hours_FE1, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This additional feature gives the same result as the baseline, with a cross validation mean of 0.75 (0.75 for the baseline) and a metric of 0.76 (0.76 for the baseline). With the number of added variables and the lack of score improvement, we reject this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Month-Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `month_day` is added to understand if patterns exist based on specific dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add month-day from 'date'\n",
    "hours_FE2 = pd.concat([hours_FE_sel,pd.DataFrame(pd.DatetimeIndex(hours_df['date']).strftime('%m-%d'))], axis=1, sort=False, ignore_index=False)\n",
    "hours_FE2.rename(columns={0:'month_day'}, inplace=True)\n",
    "\n",
    "# Encode feature\n",
    "hours_FE2 = onehot_encode_single(hours_FE2, 'month_day')\n",
    "df_desc(hours_FE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(hours_FE2, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This additional feature gives a similar result than the baseline, with a cross validation mean of 0.78 (0.75 for the baseline) and a metric of 0.75 (0.76 for the baseline). With the number of added variables and the lack of score improvement, we reject this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predefined Peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `predefined_peak` is added to flag the periods of typically high utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_FE3 = hours_FE_sel.copy()\n",
    "\n",
    "def predefined_peaks(row):\n",
    "    if (row['workingday_yes'] == 1) & ((row['hour_8'] == 1) |\n",
    "                                      (row['hour_7'] == 1) |\n",
    "                                      (row['hour_16'] == 1) |\n",
    "                                      (row['hour_17'] == 1) |\n",
    "                                      (row['hour_18'] == 1) |\n",
    "                                      (row['hour_19'] == 1)):\n",
    "        return 1\n",
    "    elif (row['workingday_yes'] == 0) & ((row['hour_11'] == 1) |\n",
    "                                      (row['hour_10'] == 1) |\n",
    "                                      (row['hour_12'] == 1) |\n",
    "                                      (row['hour_13'] == 1) |\n",
    "                                      (row['hour_14'] == 1) |\n",
    "                                      (row['hour_15'] == 1) |\n",
    "                                      (row['hour_16'] == 1) |\n",
    "                                      (row['hour_17'] == 1) |\n",
    "                                      (row['hour_19'] == 1) |\n",
    "                                      (row['hour_18'] == 1)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "hours_FE3['predefined_peak'] = hours_FE3.apply(lambda row: predefined_peaks(row), axis=1)\n",
    "hours_FE3.predefined_peak.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(hours_FE3, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This additional feature significantly improves the score of the model, with a cross validation mean of 0.84 (0.75 for the baseline) and a metric of 0.83 (0.76 for the baseline). As this feature also tries to combine hours variables and `workingday_yes`, we assume it might reduce the number of features for the final metric. Thus, we accept this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_FE_sel  = hours_FE3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculated Peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `calculated_peak` is added to flag the periods of typically high utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_FE4 = hours_FE_sel.copy()\n",
    "\n",
    "#Set threshold to mean(Total_Bikes)+th based on Trial and Error appraoch\n",
    "th = 0.315\n",
    "\n",
    "def calculated_peaks(row, th):\n",
    "    if (row['total_bikes'] > (hours_FE4.total_bikes.mean()+ th *hours_FE4.total_bikes.mean())):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "hours_FE4['calculated_peak'] = hours_FE4.apply(lambda row: calculated_peaks(row, th), axis=1)\n",
    "hours_FE4.calculated_peak.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(hours_FE4, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This additional feature significantly improves the score of the model, with a cross validation mean of 0.89 (0.75 for the baseline) and a metric of 0.90 (0.76 for the baseline). Thus, we accept this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_FE_sel  = hours_FE4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference with Season Average Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `diff_season_avg_temp` is added to identify days with clement temperature compared to the seasonal average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_FE5 = hours_FE_sel.copy()\n",
    "\n",
    "def diff_season_avg_temp_calc(df, row):\n",
    "    if (row['season_spring'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.season_spring == 1].mean()\n",
    "    \n",
    "    elif (row['season_winter'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.season_winter == 1].mean()\n",
    "    \n",
    "    elif (row['season_fall'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.season_fall == 1].mean()\n",
    "    \n",
    "    elif (row['season_summer'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.season_summer == 1].mean()\n",
    "    \n",
    "hours_FE5['diff_season_avg_temp'] = hours_FE5.apply(lambda row: diff_season_avg_temp_calc(hours_FE5, row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(hours_FE5, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This additional feature gives a similar result than the previously selected features, with a cross validation mean of 0.89 (0.89 for the previously selected features) and a metric of 0.90 (0.90 for the previously selected features). With no clear score improvement, we reject this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference with Monthly Average Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `diff_month_avg_temp` is added to identify days with clement temperature compared to the monthly average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_FE6 = hours_FE_sel.copy()\n",
    "\n",
    "def diff_month_avg_temp_calc(df, row):\n",
    "    if (row['month_jan'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.month_jan == 1].mean()\n",
    "    \n",
    "    elif (row['month_feb'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.month_feb == 1].mean()\n",
    "    \n",
    "    elif (row['month_mar'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.month_mar == 1].mean()\n",
    "    \n",
    "    elif (row['month_apr'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.month_apr == 1].mean()\n",
    "    \n",
    "    elif (row['month_may'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.month_may == 1].mean()\n",
    "    \n",
    "    elif (row['month_jun'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.month_jun == 1].mean()\n",
    "    \n",
    "    elif (row['month_jul'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.month_jul == 1].mean()\n",
    "    \n",
    "    elif (row['month_aug'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.month_aug == 1].mean()\n",
    "    \n",
    "    elif (row['month_sep'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.month_sep == 1].mean()\n",
    "    \n",
    "    elif (row['month_oct'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.month_oct == 1].mean()\n",
    "    \n",
    "    elif (row['month_nov'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.month_nov == 1].mean()\n",
    "    \n",
    "    elif (row['month_dec'] == 1):\n",
    "        return row['actual_temp'] - df.actual_temp[df.month_dec == 1].mean()\n",
    "    \n",
    "hours_FE6['diff_month_avg_temp'] = hours_FE6.apply(lambda row: diff_month_avg_temp_calc(hours_FE6, row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(hours_FE6, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This additional feature gives a similar result than the previously selected features, with a cross validation mean of 0.89 (0.89 for the previously selected features) and a metric of 0.90 (0.90 for the previously selected features). With no clear score improvement, we reject this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference with Season Average Humidity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `diff_season_avg_humi` is added to identify days with clement humidity compared to the seasonal average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_FE7 = hours_FE_sel.copy()\n",
    "\n",
    "def diff_season_avg_humi_calc(df, row):\n",
    "    if (row['season_spring'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.season_spring == 1].mean()\n",
    "    \n",
    "    elif (row['season_winter'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.season_winter == 1].mean()\n",
    "    \n",
    "    elif (row['season_fall'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.season_fall == 1].mean()\n",
    "    \n",
    "    elif (row['season_summer'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.season_summer == 1].mean()\n",
    "    \n",
    "hours_FE7['diff_season_avg_humi'] = hours_FE7.apply(lambda row: diff_season_avg_humi_calc(hours_FE7, row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(hours_FE7, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This additional feature gives a similar result than the previously selected features, with a cross validation mean of 0.89 (0.89 for the previously selected features) and a metric of 0.90 (0.90 for the previously selected features). With no clear score improvement, we reject this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference with Monthly Average Humidity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `diff_month_avg_humi` is added to identify days with clement humidity compared to the monthly average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_FE8 = hours_FE_sel.copy()\n",
    "\n",
    "def diff_month_avg_humi_calc(df, row):\n",
    "    if (row['month_jan'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.month_jan == 1].mean()\n",
    "    \n",
    "    elif (row['month_feb'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.month_feb == 1].mean()\n",
    "    \n",
    "    elif (row['month_mar'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.month_mar == 1].mean()\n",
    "    \n",
    "    elif (row['month_apr'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.month_apr == 1].mean()\n",
    "    \n",
    "    elif (row['month_may'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.month_may == 1].mean()\n",
    "    \n",
    "    elif (row['month_jun'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.month_jun == 1].mean()\n",
    "    \n",
    "    elif (row['month_jul'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.month_jul == 1].mean()\n",
    "    \n",
    "    elif (row['month_aug'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.month_aug == 1].mean()\n",
    "    \n",
    "    elif (row['month_sep'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.month_sep == 1].mean()\n",
    "    \n",
    "    elif (row['month_oct'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.month_oct == 1].mean()\n",
    "    \n",
    "    elif (row['month_nov'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.month_nov == 1].mean()\n",
    "    \n",
    "    elif (row['month_dec'] == 1):\n",
    "        return row['humidity'] - df.humidity[df.month_dec == 1].mean()\n",
    "    \n",
    "hours_FE8['diff_month_avg_humi'] = hours_FE8.apply(lambda row: diff_month_avg_humi_calc(hours_FE8, row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(hours_FE8, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This additional feature gives a similar result than the previously selected features, with a cross validation mean of 0.89 (0.89 for the previously selected features) and a metric of 0.90 (0.90 for the previously selected features). With no clear score improvement, we reject this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polynomial variables `actual_temp_poly_2`, `actual_temp_poly_3`, `humidity_poly_2`, `humidity_poly_3`, `windspeed_poly_2`, `windspeed_poly_3` are added to identify potential polynomial relationship between the target and the corresponding variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_FE9 = hours_FE_sel.copy()\n",
    "degree = 3\n",
    "poly = PolynomialFeatures(degree)\n",
    "list_var = ['actual_temp', 'humidity', 'windspeed']\n",
    "\n",
    "def add_poly(df, degree, list_var):\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    for var in list_var:\n",
    "        poly_mat = poly.fit_transform(df[var].values.reshape(-1,1))\n",
    "        for i in range(2, degree+1):\n",
    "            df[var + '_poly_' + str(i)] = poly_mat[:,i]    \n",
    "\n",
    "add_poly(hours_FE9, degree, list_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(hours_FE9, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This additional feature gives a similar result than the previously selected features, with a cross validation mean of 0.90 (0.89 for the previously selected features) and a metric of 0.90 (0.90 for the previously selected features). With no clear score improvement, we reject this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hours Bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hour variables seem to be important for the model, but they are numerous. In order to reduce the number of variables, they will be binned into similar ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_FE10 = hours_FE_sel.copy()\n",
    "\n",
    "def bin_hours(row):\n",
    "    if (row['hour_0'] == 1) | (row['hour_1'] == 1) | (row['hour_2'] == 1) | (row['hour_3'] == 1) :\n",
    "        return '00-03'\n",
    "    \n",
    "    if (row['hour_4'] == 1) | (row['hour_5'] == 1) | (row['hour_6'] == 1) | (row['hour_7'] == 1) :\n",
    "        return '04-07'\n",
    "    \n",
    "    if (row['hour_8'] == 1) | (row['hour_9'] == 1) | (row['hour_10'] == 1) | (row['hour_11'] == 1):\n",
    "        return '08-11'\n",
    "    \n",
    "    if (row['hour_12'] == 1) | (row['hour_13'] == 1) | (row['hour_14'] == 1) | (row['hour_15'] == 1): \n",
    "        return '12-15'\n",
    "    \n",
    "    if (row['hour_16'] == 1) | (row['hour_17'] == 1) |(row['hour_18'] == 1) | (row['hour_19'] == 1):\n",
    "        return '16-19'\n",
    "    \n",
    "    if (row['hour_20'] == 1) | (row['hour_21'] == 1) | (row['hour_22'] == 1) | (row['hour_23'] == 1):\n",
    "        return '20-23'\n",
    "\n",
    "hours_FE10['hours'] = hours_FE10.apply(lambda row: bin_hours(row), axis=1)\n",
    "hours_FE10.hours.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_FE10 = onehot_encode_single(hours_FE10, 'hours')\n",
    "hours_FE10.drop(['hour_0', 'hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23'],axis=1, inplace=True)\n",
    "df_desc(hours_FE10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(hours_FE10, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_FE_sel_lite = hours_FE10.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This additional feature decrease slightly the results with the previously selected features, with a cross validation mean of 0.85 (0.89 for the previously selected features) and a metric of 0.87 (0.90 for the previously selected features). However, it decreases significantly the number of features from 59 to 40. The resulting dataset will be kept to be tested during the Features Selection phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_outliers  = hours_FE_sel.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, target, columns):\n",
    "    x = df[columns]\n",
    "    y = df[target]\n",
    "    ols = sm.OLS(endog = y.astype(float), exog = x.astype(float))\n",
    "    fit = ols.fit()\n",
    "    test = fit.outlier_test()['bonf(p)']\n",
    "    outliers = list(test[test<1e-3].index)\n",
    "    df.drop(df.index[outliers], inplace = True)\n",
    "    df.reset_index(drop=True, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hours_outliers = remove_outliers(hours_outliers, 'total_bikes', ['actual_temp' , 'humidity', 'windspeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_outliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_FE_sel.equals(hours_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('Dataset:', hours_FE_sel.shape[0],'rows |', hours_FE_sel.shape[1], 'columns'))\n",
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('Dataset:', hours_outliers.shape[0],'rows |', hours_outliers.shape[1], 'columns'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numerical features have been tested for outliers, but no outlier has been found. The *lite* version of the dataset with binned hours will be proceeded as well for process consistency, even if no outlier should be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_outliers_lite  = hours_FE_sel_lite.copy()\n",
    "hours_outliers_lite = remove_outliers(hours_outliers_lite, 'total_bikes', ['actual_temp' , 'humidity', 'windspeed'])\n",
    "hours_FE_sel_lite.equals(hours_outliers_lite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('{:<9} {:>6} {:>6} {:>3} {:>6}'.format('Dataset:', hours_outliers.shape[0],'rows |', hours_outliers.shape[1], 'columns'))\n",
    "print()\n",
    "pipeline(hours_outliers, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset resulting from the Feature Engineering phase contains 59 features, with a model reaching the accuracy of 0.90. The Feature Selection phase aims to reduce the number of variables used by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Recursive Feature Elimination (RFE) method is used to select the most relevant features for the model. In order to find which number of features provides the best score, the dataset will be tested against each possibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_rfe_multi(df, target, algorithm, range_def, scores):\n",
    "    features = list_features(df, target)\n",
    "    X, X_train, X_test, y, y_train, y_test = train_test_split_0(df, target, features)\n",
    "    print('Iterations:')\n",
    "    for i in range_def:\n",
    "        rfe = RFE(algorithm, i)\n",
    "        rfe = rfe.fit(X, y.values.ravel())\n",
    "        \n",
    "        cols_rfe = list(X.loc[:, rfe.support_])\n",
    "        X_rfe_sel = X_train[cols_rfe]\n",
    "        X_rfe_test_sel = X_test[cols_rfe]\n",
    "\n",
    "        algorithm.fit(X_rfe_sel, y_train)\n",
    "        y_pred = algorithm.predict(X_rfe_test_sel)\n",
    "        \n",
    "        result_model = [i, '{:.2f}'.format(r2_score(y_test, y_pred)), cols_rfe]\n",
    "        scores.loc[i] = result_model\n",
    "        print(i, end='   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(columns=['features','score', 'cols'])\n",
    "range_def = range(1, len(hours_outliers.columns))\n",
    "pipeline_rfe_multi(hours_outliers, 'total_bikes', lm, range_def, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores['features'] = scores['features'].astype('float')\n",
    "scores['score'] = scores['score'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = scores['features'],\n",
    "             y = scores['score'],\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores.nlargest(10, 'score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RFE doesn't reduce drastically the number of features without degrading the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination on *Lite* Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *lite* version using the binnbed hours will be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores_lite = pd.DataFrame(columns=['features','score', 'cols'])\n",
    "range_def = range(1, len(hours_outliers_lite.columns))\n",
    "pipeline_rfe_multi(hours_outliers_lite, 'total_bikes', lm, range_def, scores_lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_lite['features'] = scores_lite['features'].astype('float')\n",
    "scores_lite['score'] = scores_lite['score'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = scores_lite['features'],\n",
    "             y = scores_lite['score'],\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_lite.nlargest(10, 'score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score can remain at 0.87 with only 38 features when the hours are binned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features seem to have a lower importance for the model. They will be manually removed from the dataset with binned hours to see how the score gets degrated:  \n",
    "- The meteorological features would simplify the inputs for the model, if removed. Thus, `actual_temp`, `humidity`, `windspeed` and the `weather_condition` categorical variables will be removed.  \n",
    "- The `workingday_yes` variable is also removed, as it most of the time duplicates information already conveyed by the weekdays and predefined peak variables - it would need to compromise with a loss of performance on holidays.  \n",
    "- The seasons variables also most of the time are doublons with the months variables - not using them would only sacrifice on some performance for the few weeks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_manual = hours_outliers_lite.copy()\n",
    "hours_manual.drop(['actual_temp', 'humidity', 'windspeed', 'weather_condition_clear',\n",
    "                   'weather_condition_mist', 'weather_condition_light_rain', 'weather_condition_heavy_rain',\n",
    "                   'workingday_yes',\n",
    "                   'season_fall', 'season_summer', 'season_spring', 'season_winter'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores_manual = pd.DataFrame(columns=['features','score', 'cols'])\n",
    "range_def = range(1, len(hours_manual.columns))\n",
    "pipeline_rfe_multi(hours_manual, 'total_bikes', lm, range_def, scores_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_manual['features'] = scores_manual['features'].astype('float')\n",
    "scores_manual['score'] = scores_manual['score'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Line Plot\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = scores_manual['features'],\n",
    "             y = scores_manual['score'],\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores_manual.nlargest(10, 'score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(scores_manual.iloc[27]['cols']) - set(scores_manual.iloc[25]['cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(hours_manual, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a simpllified hours notation and keeping only information of time and peaks allow the model to reach a score of 0.85 with only 28 variables. It is also important to note that the two (2) additional features describing the utilization peaks allow the score to jump from 0.61 to 0.85."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_manual_rain = hours_outliers_lite.copy()\n",
    "hours_manual_rain.drop(['actual_temp', 'humidity', 'windspeed',\n",
    "                        'workingday_yes',\n",
    "                        'season_fall', 'season_summer', 'season_spring', 'season_winter'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipeline(hours_manual_rain, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding back the rain information `weather_condition`, the model can integrate a simple weather input to slightly precise its predictions and reach a score of 0.86. The model now uses 32 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_manual_full_weather = hours_outliers_lite.copy()\n",
    "hours_manual_full_weather.drop(['workingday_yes',\n",
    "                                'season_fall', 'season_summer', 'season_spring', 'season_winter'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipeline(hours_manual_full_weather, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a more precise meteorological information is taken in account, the model can reach a score of 0.87 with 35 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_manual_hourly = hours_outliers.copy()\n",
    "hours_manual_hourly.drop(['workingday_yes',\n",
    "                          'season_fall', 'season_summer', 'season_spring', 'season_winter'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(hours_manual_hourly, 'total_bikes', lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if a precise hourly monitoring is required, the model can reach a score of 0.88 with 54 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>__Confirm by changing the number of folds.__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Feature Selection phase suggested several acceptable models, which mainly differ on the number of features used and the resulting performance. Depending on the accuracy expected by the business, one of these models will be selected:  \n",
    "\n",
    "1. Time and Utilization Peaks information only:  \n",
    "Score: 0.85 | Features: 28    \n",
    "\n",
    "\n",
    "2. Model with Simple Rain information:  \n",
    "Score: 0.86 | Features: 32  \n",
    "\n",
    "\n",
    "3. Model with Complete Weather information:  \n",
    "Score: 0.87 | Features: 35  \n",
    "\n",
    "\n",
    "4. Model with Hourly information:  \n",
    "Score: 0.88 | Features: 54  \n",
    "\n",
    "\n",
    "5. Complete Model:  \n",
    "Score: 0.90 | Features: 59  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "*Vratul Kapur | Irune Maury Arrue | Paul Jacques-Mignault | Sheena Miles | Ashley O’Mahony | Stavros Tsentemeidis | Karl Westphal  \n",
    "O17 (Group G) | Master in Big Data and Business Analytics | Oct 2018 Intake | IE School of Human Sciences and Technology*\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "432px",
    "width": "339px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "360px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
